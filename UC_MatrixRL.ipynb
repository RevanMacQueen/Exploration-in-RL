{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import copy\n",
    "from scipy.stats import bernoulli\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    '''General RL environment'''\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    def advance(self, action):\n",
    "        '''\n",
    "        Moves one step in the environment.\n",
    "        Args:\n",
    "            action\n",
    "        Returns:\n",
    "            reward - double - reward\n",
    "            newState - int - new state\n",
    "            pContinue - 0/1 - flag for end of the episode\n",
    "        '''\n",
    "        return 0, 0, 0\n",
    "\n",
    "def make_riverSwim(epLen=20, nState=5):\n",
    "    '''\n",
    "    Makes the benchmark RiverSwim MDP.\n",
    "    Args:\n",
    "        NULL - works for default implementation\n",
    "    Returns:\n",
    "        riverSwim - Tabular MDP environment '''\n",
    "    nAction = 2\n",
    "    R_true = {}\n",
    "    P_true = {}\n",
    "    states = {}\n",
    "    for s in range(nState):\n",
    "        states[(s)] = 0.0\n",
    "        for a in range(nAction):\n",
    "            R_true[s, a] = (0, 0)\n",
    "            P_true[s, a] = np.zeros(nState)\n",
    "\n",
    "    # Rewards\n",
    "    R_true[0, 0] = (5/1000, 0)\n",
    "    R_true[nState - 1, 1] = (1, 0)\n",
    "\n",
    "    # Transitions\n",
    "    for s in range(nState):\n",
    "        P_true[s, 0][max(0, s-1)] = 1.\n",
    "\n",
    "    for s in range(1, nState - 1):\n",
    "        P_true[s, 1][min(nState - 1, s + 1)] = 0.3\n",
    "        P_true[s, 1][s] = 0.6\n",
    "        P_true[s, 1][max(0, s-1)] = 0.1\n",
    "\n",
    "    P_true[0, 1][0] = 0.3\n",
    "    P_true[0, 1][1] = 0.7\n",
    "    P_true[nState - 1, 1][nState - 1] = 0.9\n",
    "    P_true[nState - 1, 1][nState - 2] = 0.1\n",
    "\n",
    "    riverSwim = TabularMDP(nState, nAction, epLen)\n",
    "    riverSwim.R = R_true\n",
    "    riverSwim.P = P_true\n",
    "    riverSwim.states = states\n",
    "    riverSwim.reset()\n",
    "\n",
    "    return riverSwim\n",
    "\n",
    "class TabularMDP(Environment):\n",
    "    '''\n",
    "    Tabular MDP\n",
    "    R - dict by (s,a) - each R[s,a] = (meanReward, sdReward)\n",
    "    P - dict by (s,a) - each P[s,a] = transition vector size S\n",
    "    '''\n",
    "\n",
    "    def __init__(self, nState, nAction, epLen):\n",
    "        '''\n",
    "        Initialize a tabular episodic MDP\n",
    "        Args:\n",
    "            nState  - int - number of states\n",
    "            nAction - int - number of actions\n",
    "            epLen   - int - episode length\n",
    "        Returns:\n",
    "            Environment object\n",
    "        '''\n",
    "\n",
    "        self.nState = nState\n",
    "        self.nAction = nAction\n",
    "        self.epLen = epLen\n",
    "\n",
    "        self.timestep = 0\n",
    "        self.state = 0\n",
    "\n",
    "        # Now initialize R and P\n",
    "        self.R = {}\n",
    "        self.P = {}\n",
    "        self.states = {}\n",
    "        for state in range(nState):\n",
    "            for action in range(nAction):\n",
    "                self.R[state, action] = (1, 1)\n",
    "                self.P[state, action] = np.ones(nState) / nState\n",
    "\n",
    "    def reset(self):\n",
    "        \"Resets the Environment\"\n",
    "        self.timestep = 0\n",
    "        self.state = 0\n",
    "\n",
    "    def advance(self,action):\n",
    "        '''\n",
    "        Move one step in the environment\n",
    "        Args:\n",
    "        action - int - chosen action\n",
    "        Returns:\n",
    "        reward - double - reward\n",
    "        newState - int - new state\n",
    "        episodeEnd - 0/1 - flag for end of the episode\n",
    "        '''\n",
    "        if self.R[self.state, action][1] < 1e-9:\n",
    "            # Hack for no noise\n",
    "            reward = self.R[self.state, action][0]\n",
    "        else:\n",
    "            reward = np.random.normal(loc=self.R[self.state, action][0],\n",
    "                                      scale=self.R[self.state, action][1])\n",
    "        #print(self.state, action, self.P[self.state, action])\n",
    "        newState = np.random.choice(self.nState, p=self.P[self.state, action])\n",
    "\n",
    "        # Update the environment\n",
    "        self.state = newState\n",
    "        self.timestep += 1\n",
    "\n",
    "        episodeEnd = 0\n",
    "        if self.timestep == self.epLen:\n",
    "            episodeEnd = 1\n",
    "            #newState = None\n",
    "            self.reset()\n",
    "\n",
    "        return reward, newState, episodeEnd\n",
    "\n",
    "    def argmax(self,b):\n",
    "        #print(b)\n",
    "        return np.random.choice(np.where(b == b.max())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UC_MatrixRL(object):\n",
    "    def __init__(self,env,N):\n",
    "        self.env = env\n",
    "        #See Step 3 of Algorithm 1\n",
    "        self.N = N \n",
    "        #The dimensionality of phi(s,a), see Step 2 or Assumption 1\n",
    "        self.d1 = self.env.nState * self.env.nAction\n",
    "        #The dimensionality of psi(s'), see Step 2 or Assumption 1\n",
    "        self.d2 = self.env.nState\n",
    "        #Step 2\n",
    "        self.features_state_action = {(s,a): np.zeros(self.d1) for s in self.env.states.keys() for a in range(self.env.nAction)}\n",
    "        #Step 3\n",
    "        self.features_next_state = {(s): np.zeros(self.d2) for s in self.env.states.keys()}\n",
    "        # A hack for using numpy's linear algebra functions in Step 4\n",
    "        self.features_next_state_mat = np.identity(self.d2)\n",
    "        # Creates the Identity Matrix for a dictionary\n",
    "        self.createIdentity()\n",
    "        # Initialize our Q matrix\n",
    "        self.Q = {(h,s,a): 0.0 for h in range(self.env.epLen) for s in self.env.states.keys() \\\n",
    "                   for a in range(self.env.nAction)}\n",
    "        #Step 4\n",
    "        self.A = np.identity(self.d1)\n",
    "        #For use in the Sherman-Morrison Update\n",
    "        self.Ainv = np.linalg.inv(self.A)\n",
    "        #Step 4\n",
    "        self.M = np.zeros((self.d1,self.d2))\n",
    "        #See Assumptions 2,2' and Theorem 1, this equals 1 in the tabular case\n",
    "        self.C_phi = 1.0 \n",
    "        # See Assumption 2'(Stronger Feature Regularity), and consider the case when v_1 = v_2 = ....\n",
    "        self.C_psi = np.sqrt(env.nState) \n",
    "        # See Theorem 1\n",
    "        self.C_M = 1.0 \n",
    "        # See Theorem 1\n",
    "        self.C_psi_ = 1.0 \n",
    "        # This value scales our confidence interval, must be > 0\n",
    "        self.c = 1.0 \n",
    "        # For use in updating M_n, see Step 13 and Eqn (2)\n",
    "        self.sums = np.zeros((self.d1,self.d2))\n",
    "        #Creates K_psi, see Section 3.1: Estimating the core matrix.\n",
    "        self.createK()\n",
    "    \n",
    "    def createK(self):\n",
    "        '''\n",
    "        A function that creates K_psi and (K_psi)^-1 for use in the Sherman-Morrison Update\n",
    "        See Section 3.1: Estimating the core matrix\n",
    "        '''\n",
    "        self.K = np.zeros((self.d2,self.d2))\n",
    "        for s_ in self.env.states.keys():\n",
    "            self.K = self.K + np.outer(self.features_next_state[s_],self.features_next_state[s_])\n",
    "        self.Kinv = np.linalg.inv(self.K)\n",
    "    \n",
    "    def act(self,s,h):\n",
    "        '''\n",
    "        A function that returns the argmax of Q given the state and timestep\n",
    "        '''\n",
    "        return self.env.argmax(np.array([self.Q[(h,s,a)] for a in range(self.env.nAction)]))\n",
    "    \n",
    "    def createIdentity(self):\n",
    "        '''\n",
    "            A function that creates the Identity Matrix for a Dictionary\n",
    "        '''\n",
    "        i = 0 \n",
    "        for key in self.features_state_action.keys():\n",
    "            self.features_state_action[key][i] = 1\n",
    "            i += 1\n",
    "        j = 0\n",
    "        for key in self.features_next_state.keys():\n",
    "            self.features_next_state[key][j] = 1\n",
    "            j += 1\n",
    "    \n",
    "    def proj(self, x, lo, hi):\n",
    "        '''Projects the value of x into the [lo,hi] interval'''\n",
    "        return max(min(x,hi),lo)\n",
    "    \n",
    "    def compute_Q(self,n):\n",
    "        '''\n",
    "        A function that computes the Optimisic Q-Values, see step 6 and Equations 4,8. \n",
    "        '''\n",
    "        Q = {(h,s,a): 0.0 for h in range(self.env.epLen) for s in self.env.states.keys() \\\n",
    "                   for a in range(self.env.nAction)}\n",
    "        V = np.zeros((env.epLen+1,env.nState))\n",
    "        for h in range(self.env.epLen-1,-1,-1):\n",
    "            for s in self.env.states.keys():\n",
    "                for a in range(self.env.nAction):\n",
    "                    r = env.R[s,a][0]\n",
    "                    \n",
    "                    value = np.dot(np.matmul(np.dot(self.features_state_action[s,a].T,self.M),\\\n",
    "                            self.features_next_state_mat),V[h+1,:])\n",
    "                    \n",
    "                    bonus = 2 * self.C_psi * np.sqrt(self.Beta(n)) * np.dot(\\\n",
    "                            np.dot(self.features_state_action[s,a],self.Ainv),self.features_state_action[s,a])\n",
    "                        \n",
    "                    Q[h,s,a] = self.proj(r+value+bonus,0,env.epLen)\n",
    "                V[h,s] = max(np.array([self.Q[(h,s,a)] for a in range(self.env.nAction)]))\n",
    "        self.Q = Q.copy()\n",
    "        \n",
    "    def Beta(self,n):\n",
    "        '''\n",
    "        A function that computes Beta under the Assumption Theorem 2 holds, see equation 8\n",
    "        '''\n",
    "        first = self.c*(self.C_M * self.C_psi_ ** 2)\n",
    "        second = np.log(n*self.env.epLen*self.C_phi)*self.d1\n",
    "        return first * second\n",
    "    \n",
    "    def update_core_matrix(self,s,a,s_):\n",
    "        '''\n",
    "        A function that performs step 12 and 13. \n",
    "        '''\n",
    "        self.A = self.A + np.outer(self.features_state_action[s,a],self.features_state_action[s,a])\n",
    "        \n",
    "        self.Ainv = self.Ainv - np.dot((np.outer(np.dot(self.Ainv,self.features_state_action[s,a]) \\\n",
    "                 ,self.features_state_action[s,a])),self.Ainv) / \\\n",
    "                    (1 + np.dot(np.dot(self.features_state_action[s,a],self.Ainv),self.features_state_action[s,a]))\n",
    "        \n",
    "        self.sums = self.sums + np.outer(self.features_state_action[s,a],self.features_next_state[s_])\n",
    "        \n",
    "        self.M = np.matmul(np.matmul(self.Ainv,self.sums),self.Kinv)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_riverSwim(epLen = 60, nState = 15)\n",
    "N = 1000\n",
    "agent = UC_MatrixRL(env,N)\n",
    "R = 0\n",
    "Rvec = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80374a8a36254798b6f711b7bebd276d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for n in tqdm(range(1,N+1)):\n",
    "    env.reset()\n",
    "    done = 0\n",
    "    agent.compute_Q(n)\n",
    "    while not done:\n",
    "        s = env.state\n",
    "        h = env.timestep\n",
    "        a = agent.act(s,h)\n",
    "        r,s_,done = env.advance(a)\n",
    "        R += r\n",
    "        agent.update_core_matrix(s,a,s_)\n",
    "    Rvec.append(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a22973ac8>]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Rvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2-norm of (True Transition Probabiltites - Estimated Probabilities) is: 0.049222871653962844\n"
     ]
    }
   ],
   "source": [
    "true_p = []\n",
    "for values in env.P.values():\n",
    "    for value in values:\n",
    "        true_p.append(value)\n",
    "        \n",
    "estimated_p = []\n",
    "for values in agent.M:\n",
    "    for value in values:\n",
    "        estimated_p.append(value)\n",
    "        \n",
    "print('The 2-norm of (True Transition Probabiltites - Estimated Probabilities) is:',np.linalg.norm(np.subtract(true_p,estimated_p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
