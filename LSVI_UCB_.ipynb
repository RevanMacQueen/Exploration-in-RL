{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from scipy.stats import bernoulli\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    '''General RL environment'''\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    def advance(self, action):\n",
    "        '''\n",
    "        Moves one step in the environment.\n",
    "        Args:\n",
    "            action\n",
    "        Returns:\n",
    "            reward - double - reward\n",
    "            newState - int - new state\n",
    "            pContinue - 0/1 - flag for end of the episode\n",
    "        '''\n",
    "        return 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_riverSwim(epLen=20, nState=5):\n",
    "    '''\n",
    "    Makes the benchmark RiverSwim MDP.\n",
    "    Args:\n",
    "        NULL - works for default implementation\n",
    "    Returns:\n",
    "        riverSwim - Tabular MDP environment '''\n",
    "    nAction = 2\n",
    "    R_true = {}\n",
    "    P_true = {}\n",
    "    states = {}\n",
    "    for s in range(nState):\n",
    "        states[(s)] = 0.0\n",
    "        for a in range(nAction):\n",
    "            R_true[s, a] = (0, 0)\n",
    "            P_true[s, a] = np.zeros(nState)\n",
    "\n",
    "    # Rewards\n",
    "    R_true[0, 0] = (5/1000, 0)\n",
    "    R_true[nState - 1, 1] = (1, 0)\n",
    "\n",
    "    # Transitions\n",
    "    for s in range(nState):\n",
    "        P_true[s, 0][max(0, s-1)] = 1.\n",
    "\n",
    "    for s in range(1, nState - 1):\n",
    "        P_true[s, 1][min(nState - 1, s + 1)] = 0.3\n",
    "        P_true[s, 1][s] = 0.6\n",
    "        P_true[s, 1][max(0, s-1)] = 0.1\n",
    "\n",
    "    P_true[0, 1][0] = 0.3\n",
    "    P_true[0, 1][1] = 0.7\n",
    "    P_true[nState - 1, 1][nState - 1] = 0.9\n",
    "    P_true[nState - 1, 1][nState - 2] = 0.1\n",
    "\n",
    "    riverSwim = TabularMDP(nState, nAction, epLen)\n",
    "    riverSwim.R = R_true\n",
    "    riverSwim.P = P_true\n",
    "    riverSwim.states = states\n",
    "    riverSwim.reset()\n",
    "\n",
    "    return riverSwim\n",
    "\n",
    "class TabularMDP(Environment):\n",
    "    '''\n",
    "    Tabular MDP\n",
    "    R - dict by (s,a) - each R[s,a] = (meanReward, sdReward)\n",
    "    P - dict by (s,a) - each P[s,a] = transition vector size S\n",
    "    '''\n",
    "\n",
    "    def __init__(self, nState, nAction, epLen):\n",
    "        '''\n",
    "        Initialize a tabular episodic MDP\n",
    "        Args:\n",
    "            nState  - int - number of states\n",
    "            nAction - int - number of actions\n",
    "            epLen   - int - episode length\n",
    "        Returns:\n",
    "            Environment object\n",
    "        '''\n",
    "\n",
    "        self.nState = nState\n",
    "        self.nAction = nAction\n",
    "        self.epLen = epLen\n",
    "\n",
    "        self.timestep = 0\n",
    "        self.state = 0\n",
    "\n",
    "        # Now initialize R and P\n",
    "        self.R = {}\n",
    "        self.P = {}\n",
    "        self.states = {}\n",
    "        for state in range(nState):\n",
    "            for action in range(nAction):\n",
    "                self.R[state, action] = (1, 1)\n",
    "                self.P[state, action] = np.ones(nState) / nState\n",
    "                \n",
    "    def reset(self):\n",
    "        \"Resets the Environment\"\n",
    "        self.timestep = 0\n",
    "        self.state = 0\n",
    "        \n",
    "    def advance(self,action):\n",
    "        '''\n",
    "        Move one step in the environment\n",
    "        Args:\n",
    "        action - int - chosen action\n",
    "        Returns:\n",
    "        reward - double - reward\n",
    "        newState - int - new state\n",
    "        episodeEnd - 0/1 - flag for end of the episode\n",
    "        '''\n",
    "        if self.R[self.state, action][1] < 1e-9:\n",
    "            # Hack for no noise\n",
    "            reward = self.R[self.state, action][0]\n",
    "        else:\n",
    "            reward = np.random.normal(loc=self.R[self.state, action][0],\n",
    "                                      scale=self.R[self.state, action][1])\n",
    "        #print(self.state, action, self.P[self.state, action])\n",
    "        newState = np.random.choice(self.nState, p=self.P[self.state, action])\n",
    "        \n",
    "        # Update the environment\n",
    "        self.state = newState\n",
    "        self.timestep += 1\n",
    "\n",
    "        episodeEnd = 0\n",
    "        if self.timestep == self.epLen:\n",
    "            episodeEnd = 1\n",
    "            #newState = None\n",
    "            self.reset()\n",
    "\n",
    "        return reward, newState, episodeEnd\n",
    "    \n",
    "    def argmax(self,b):\n",
    "        #print(b)\n",
    "        return np.random.choice(np.where(b == b.max())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deep_sea(Environment):\n",
    "    '''\n",
    "    Description:\n",
    "        A deep sea environment, where a diver goes\n",
    "        down and each time and she needs to make a\n",
    "        decision to go left or right.\n",
    "        environment terminates after fixed time step\n",
    "\n",
    "    Observation:\n",
    "        [horizontal position, vertical position]\n",
    "\n",
    "    Actions:\n",
    "        2 possible actions:\n",
    "        0 - left\n",
    "        1 - right\n",
    "\n",
    "    Starting State:\n",
    "        start at position 0, time step 0\n",
    "\n",
    "    Episode termination:\n",
    "        Env terminates after fixed number of time steps\n",
    "    '''\n",
    "\n",
    "    def __init__(self, num_steps):\n",
    "        '''\n",
    "        Inputs:\n",
    "            num_steps: An integer that represents the size of the DeepSea environment\n",
    "        '''\n",
    "        self.num_steps = num_steps\n",
    "        self.epLen = num_steps\n",
    "        self.flip_mask = 2*np.random.binomial(1,0.5,(num_steps,num_steps))-1\n",
    "        self.nAction = 2\n",
    "        self.nState = pow(num_steps,2)\n",
    "        self.epLen = num_steps\n",
    "        self.R = {}\n",
    "        self.states = {}\n",
    "        for s in range(self.num_steps):\n",
    "            for s_ in range(self.num_steps):\n",
    "                self.R[(s,s_), 0] = (0, 0)\n",
    "                self.R[(s,s_), 1] = (-0.01/self.nState, 0)\n",
    "                self.states[(s,s_)] = 0\n",
    "        self.R[(self.num_steps-1,self.num_steps-1),1] = (0.99,0)\n",
    "\n",
    "    def name(self):\n",
    "        return  \"deep sea\"\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = (0,0)\n",
    "        self.timestep = 0\n",
    "        return copy.deepcopy(self.state)\n",
    "\n",
    "    def advance(self,action):\n",
    "        assert action in [0,1], \"invalid action\"\n",
    "        self.state_prev = self.state\n",
    "        step_horizontal = (2*action-1)\n",
    "        horizontal = max(self.state[0] + step_horizontal, 0)\n",
    "        vertical = self.state[1] + 1\n",
    "        done =  bool(vertical == self.num_steps)\n",
    "        self.state = (horizontal, vertical)\n",
    "        self.timestep += 1\n",
    "        return self.R[self.state_prev,action][0], copy.deepcopy(self.state), done\n",
    "\n",
    "    def argmax(self,b):\n",
    "        return np.random.choice(np.where(b == b.max())[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSVI_UCB(object):\n",
    "    def __init__(self,env,K,c):\n",
    "        self.env = env\n",
    "        self.K = K\n",
    "        self.d = self.env.nState * self.env.nAction\n",
    "        self.c = c\n",
    "        self.p = 10/self.K\n",
    "        self.lam = 1.0\n",
    "        self.Lam = [(self.lam*np.identity(self.d)) for h in range(env.epLen)]\n",
    "        self.phi = np.identity(self.d)\n",
    "        self.Q = {(h,s,a): 0.0 for h in range(self.env.epLen+1) for s in self.env.states.keys() \\\n",
    "                   for a in range(self.env.nAction)}\n",
    "        self.w = [np.zeros(self.d) for h in range(env.epLen)]\n",
    "        self.wsum = [np.zeros(self.d) for h in range(env.epLen)]\n",
    "        self.buffer = {h: [] for h in range(self.env.epLen)}\n",
    "        self.sigma = {}\n",
    "        self.createSigma()\n",
    "        \n",
    "    def learn(self,s,a,r,s_,h):\n",
    "        self.Lam[h] += np.outer(self.phi[self.sigma[s,a]],self.phi[self.sigma[s,a]])\n",
    "        self.wsum[h] += self.phi[self.sigma[s,a]] * (r + \\\n",
    "                                max(np.array([self.Q[(h+1,s_,a_)] for a_ in range(self.env.nAction)])))\n",
    "        self.w[h] = np.matmul(np.linalg.inv(self.Lam[h]),self.wsum[h])\n",
    "\n",
    "    \n",
    "    def update_Q(self,k):\n",
    "        for h in range(env.epLen-1,-1,-1):\n",
    "            for s in self.env.states.keys():\n",
    "                for a in range(env.nAction):\n",
    "                    min1 = np.dot(self.w[h],self.phi[self.sigma[s,a]]) + self.Beta(h,k)* \\\n",
    "                                  np.sqrt(np.dot(np.dot(self.phi[self.sigma[s,a]].T,np.linalg.inv(self.Lam[h])) \\\n",
    "                                                  ,self.phi[self.sigma[s,a]]))\n",
    "                    min2 = self.env.epLen\n",
    "                    self.Q[h,s,a] = self.proj(min1,0,self.env.epLen)\n",
    "    \n",
    "    def Beta(self,h,k):\n",
    "        \n",
    "        first = np.sqrt(self.lam)*self.c\n",
    "        #second = np.sqrt(2*np.log(1/self.delta) + self.d*np.log((self.d*self.lam + k*self.L*self.L)/(self.d*self.lam)))\n",
    "        second = np.sqrt(2*np.log(1/self.p) + np.log(k*(np.linalg.det(self.Lam[h])) / (pow(self.lam,self.d))))\n",
    "        return first + second\n",
    "        \n",
    "        \n",
    "        #itoa = np.log(2*self.d*self.K*self.env.epLen/self.p)\n",
    "        #return self.c*self.d*self.env.epLen*np.sqrt(itoa)\n",
    "    \n",
    "    def createSigma(self):\n",
    "        '''\n",
    "        A simple function that creates sigma according to Appendix B.\n",
    "        Here sigma is a dictionary who inputs is a tuple (s,a,s') and stores\n",
    "        the interger index to be used in our basis model P.\n",
    "        '''\n",
    "        i = 0\n",
    "        for s in self.env.states.keys():\n",
    "            for a in range(env.nAction):\n",
    "                self.sigma[(s,a)] = int(i)\n",
    "                i += 1\n",
    "    \n",
    "    def act(self,s,h):\n",
    "        x = np.array([self.Q[(h,s,a)] for a in range(self.env.nAction)])\n",
    "        return self.env.argmax(x)\n",
    "    \n",
    "    def proj(self,x, lo, hi):\n",
    "        return max(min(x,hi),lo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_riverSwim(epLen = 20, nState = 4)\n",
    "K = 2000\n",
    "c = 0.1\n",
    "agent = LSVI_UCB(env,K,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2857db13c6af4f3691dd7df866d140aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "R = 0\n",
    "Rvec = []\n",
    "for k in tqdm(range(1,K+1)):\n",
    "    env.reset()\n",
    "    done = 0\n",
    "    while done != 1:\n",
    "        s = env.state\n",
    "        h = env.timestep\n",
    "        a = agent.act(s,h)\n",
    "        r,s_,done = env.advance(a)\n",
    "        R+=r\n",
    "        agent.learn(s,a,r,s_,h)\n",
    "    Rvec.append(R)\n",
    "    agent.update_Q(k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Rvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0, 0): 3.6490481478839585,\n",
       " (0, 0, 1): 7.555222484308124,\n",
       " (0, 1, 0): 5.156997846583985,\n",
       " (0, 1, 1): 5.156997846583985,\n",
       " (0, 2, 0): 5.156997846583985,\n",
       " (0, 2, 1): 5.156997846583985,\n",
       " (0, 3, 0): 5.156997846583985,\n",
       " (0, 3, 1): 5.156997846583985,\n",
       " (1, 0, 0): 7.615234658552659,\n",
       " (1, 0, 1): 4.0402184476351755,\n",
       " (1, 1, 0): 5.713731723595637,\n",
       " (1, 1, 1): 7.553788588897214,\n",
       " (1, 2, 0): 5.713731723595637,\n",
       " (1, 2, 1): 5.713731723595637,\n",
       " (1, 3, 0): 5.713731723595637,\n",
       " (1, 3, 1): 5.713731723595637,\n",
       " (2, 0, 0): 6.194585462616494,\n",
       " (2, 0, 1): 7.446601719282658,\n",
       " (2, 1, 0): 4.380233387255729,\n",
       " (2, 1, 1): 7.588621475981621,\n",
       " (2, 2, 0): 7.438699766447427,\n",
       " (2, 2, 1): 6.194585462616494,\n",
       " (2, 3, 0): 6.194585462616494,\n",
       " (2, 3, 1): 6.194585462616494,\n",
       " (3, 0, 0): 7.43745567354171,\n",
       " (3, 0, 1): 4.332888335104482,\n",
       " (3, 1, 0): 7.26522326837608,\n",
       " (3, 1, 1): 6.127629447752938,\n",
       " (3, 2, 0): 8.120139417471798,\n",
       " (3, 2, 1): 6.127629447752938,\n",
       " (3, 3, 0): 6.127629447752938,\n",
       " (3, 3, 1): 6.127629447752938,\n",
       " (4, 0, 0): 7.219933701648295,\n",
       " (4, 0, 1): 4.000420160387589,\n",
       " (4, 1, 0): 5.657448446010879,\n",
       " (4, 1, 1): 7.991664498919454,\n",
       " (4, 2, 0): 5.657448446010879,\n",
       " (4, 2, 1): 5.657448446010879,\n",
       " (4, 3, 0): 5.657448446010879,\n",
       " (4, 3, 1): 5.657448446010879,\n",
       " (5, 0, 0): 7.198841528605569,\n",
       " (5, 0, 1): 4.2363254553212935,\n",
       " (5, 1, 0): 5.99106891354175,\n",
       " (5, 1, 1): 7.872728932203056,\n",
       " (5, 2, 0): 8.025723582624032,\n",
       " (5, 2, 1): 5.99106891354175,\n",
       " (5, 3, 0): 5.99106891354175,\n",
       " (5, 3, 1): 5.99106891354175,\n",
       " (6, 0, 0): 7.184813930500785,\n",
       " (6, 0, 1): 5.9452388129126215,\n",
       " (6, 1, 0): 7.468976215146886,\n",
       " (6, 1, 1): 4.203918680383975,\n",
       " (6, 2, 0): 5.9452388129126215,\n",
       " (6, 2, 1): 8.664045635057596,\n",
       " (6, 3, 0): 5.9452388129126215,\n",
       " (6, 3, 1): 5.9452388129126215,\n",
       " (7, 0, 0): 7.191130267133343,\n",
       " (7, 0, 1): 5.81984698764944,\n",
       " (7, 1, 0): 8.266144632971118,\n",
       " (7, 1, 1): 5.81984698764944,\n",
       " (7, 2, 0): 4.11525327043502,\n",
       " (7, 2, 1): 8.592889851601345,\n",
       " (7, 3, 0): 5.81984698764944,\n",
       " (7, 3, 1): 10.429070721878684,\n",
       " (8, 0, 0): 5.707487641953536,\n",
       " (8, 0, 1): 7.218512774659317,\n",
       " (8, 1, 0): 5.707487641953536,\n",
       " (8, 1, 1): 4.035803215163764,\n",
       " (8, 2, 0): 7.910315443505367,\n",
       " (8, 2, 1): 5.707487641953536,\n",
       " (8, 3, 0): 5.707487641953536,\n",
       " (8, 3, 1): 9.857705029638925,\n",
       " (9, 0, 0): 7.3189239270198625,\n",
       " (9, 0, 1): 6.015843312111599,\n",
       " (9, 1, 0): 7.227593111621211,\n",
       " (9, 1, 1): 4.253843600549852,\n",
       " (9, 2, 0): 6.91220530367902,\n",
       " (9, 2, 1): 6.015843312111599,\n",
       " (9, 3, 0): 6.015843312111599,\n",
       " (9, 3, 1): 9.10007260657141,\n",
       " (10, 0, 0): 7.222550000876601,\n",
       " (10, 0, 1): 5.581974002053121,\n",
       " (10, 1, 0): 3.9470516692587734,\n",
       " (10, 1, 1): 8.039170800386186,\n",
       " (10, 2, 0): 7.466378939085023,\n",
       " (10, 2, 1): 5.581974002053121,\n",
       " (10, 3, 0): 8.496269646759352,\n",
       " (10, 3, 1): 5.581974002053121,\n",
       " (11, 0, 0): 3.909210263994787,\n",
       " (11, 0, 1): 7.157245479643383,\n",
       " (11, 1, 0): 5.524922639603602,\n",
       " (11, 1, 1): 7.895160359452454,\n",
       " (11, 2, 0): 5.524922639603602,\n",
       " (11, 2, 1): 9.04313459225951,\n",
       " (11, 3, 0): 5.524922639603602,\n",
       " (11, 3, 1): 5.524922639603602,\n",
       " (12, 0, 0): 6.900224369883692,\n",
       " (12, 0, 1): 4.286775133785005,\n",
       " (12, 1, 0): 6.0624155330424925,\n",
       " (12, 1, 1): 7.028260051630631,\n",
       " (12, 2, 0): 6.0624155330424925,\n",
       " (12, 2, 1): 9.162336959592599,\n",
       " (12, 3, 0): 6.0624155330424925,\n",
       " (12, 3, 1): 11.055446305570975,\n",
       " (13, 0, 0): 6.3797820025279535,\n",
       " (13, 0, 1): 7.178374681317832,\n",
       " (13, 1, 0): 6.343940486162892,\n",
       " (13, 1, 1): 4.695983329189922,\n",
       " (13, 2, 0): 6.641123312818345,\n",
       " (13, 2, 1): 7.634281689098853,\n",
       " (13, 3, 0): 6.641123312818345,\n",
       " (13, 3, 1): 9.688142265465263,\n",
       " (14, 0, 0): 5.70642268281695,\n",
       " (14, 0, 1): 5.7089368029380125,\n",
       " (14, 1, 0): 5.971685556739289,\n",
       " (14, 1, 1): 4.7734557636510395,\n",
       " (14, 2, 0): 6.750685880343319,\n",
       " (14, 2, 1): 7.471362468298933,\n",
       " (14, 3, 0): 7.43172086844688,\n",
       " (14, 3, 1): 6.750685880343319,\n",
       " (15, 0, 0): 4.651543223808993,\n",
       " (15, 0, 1): 4.6526726577956286,\n",
       " (15, 1, 0): 4.928944141291319,\n",
       " (15, 1, 1): 4.9623774621914505,\n",
       " (15, 2, 0): 6.199182803742118,\n",
       " (15, 2, 1): 6.435333486961889,\n",
       " (15, 3, 0): 6.97215252770455,\n",
       " (15, 3, 1): 9.378233233412564,\n",
       " (16, 0, 0): 3.422571273935561,\n",
       " (16, 0, 1): 3.427468826661454,\n",
       " (16, 1, 0): 3.6389985158613816,\n",
       " (16, 1, 1): 3.6386943697702727,\n",
       " (16, 2, 0): 4.604389862102919,\n",
       " (16, 2, 1): 4.613071402869016,\n",
       " (16, 3, 0): 6.782256404466921,\n",
       " (16, 3, 1): 7.040768230108194,\n",
       " (17, 0, 0): 2.238209103788469,\n",
       " (17, 0, 1): 2.2382241178904008,\n",
       " (17, 1, 0): 2.3098287327884464,\n",
       " (17, 1, 1): 2.3156422819378566,\n",
       " (17, 2, 0): 2.947279868910808,\n",
       " (17, 2, 1): 2.95035618296337,\n",
       " (17, 3, 0): 4.779248150346591,\n",
       " (17, 3, 1): 4.91743007838127,\n",
       " (18, 0, 0): 1.1915468619184808,\n",
       " (18, 0, 1): 1.1904935036290638,\n",
       " (18, 1, 0): 1.2018833108974931,\n",
       " (18, 1, 1): 1.2031406539750602,\n",
       " (18, 2, 0): 1.5680057767071336,\n",
       " (18, 2, 1): 1.5681814055377505,\n",
       " (18, 3, 0): 2.9370466461864475,\n",
       " (18, 3, 1): 3.0126422343499835,\n",
       " (19, 0, 0): 0.44693774539688713,\n",
       " (19, 0, 1): 0.44625158808558973,\n",
       " (19, 1, 0): 0.4552374210876053,\n",
       " (19, 1, 1): 0.45601097716139005,\n",
       " (19, 2, 0): 0.5528839268768609,\n",
       " (19, 2, 1): 0.5528839268768609,\n",
       " (19, 3, 0): 1.4043265785945078,\n",
       " (19, 3, 1): 1.4048740472222796,\n",
       " (20, 0, 0): 0.0,\n",
       " (20, 0, 1): 0.0,\n",
       " (20, 1, 0): 0.0,\n",
       " (20, 1, 1): 0.0,\n",
       " (20, 2, 0): 0.0,\n",
       " (20, 2, 1): 0.0,\n",
       " (20, 3, 0): 0.0,\n",
       " (20, 3, 1): 0.0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([8.66905739, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]),\n",
       " array([8.79539988, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]),\n",
       " array([9.02032157, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]),\n",
       " array([9.3356401, 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       ]),\n",
       " array([0.        , 9.70961366, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]),\n",
       " array([ 0.        ,  9.98094098,  0.        , 10.05047119,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ]),\n",
       " array([ 9.8111075 ,  0.        ,  0.        , 10.44708081, 10.18623894,\n",
       "         0.        ,  0.        ,  0.        ]),\n",
       " array([ 9.78461048,  0.        ,  0.        , 10.34968117,  0.        ,\n",
       "        11.73865359,  0.        ,  0.        ]),\n",
       " array([ 0.        ,  9.77727666,  0.        , 10.02560631,  0.        ,\n",
       "        11.38678415,  0.        , 13.80580827]),\n",
       " array([ 9.63834198,  0.        ,  0.        ,  9.72450461,  0.        ,\n",
       "        10.75490845,  0.        , 13.29596787]),\n",
       " array([ 0.        ,  9.41589724,  0.        ,  9.33204498,  0.        ,\n",
       "         9.9640994 ,  0.        , 12.66003461]),\n",
       " array([2.50000000e-03, 8.95805821e+00, 0.00000000e+00, 9.11264926e+00,\n",
       "        8.85259246e+00, 0.00000000e+00, 0.00000000e+00, 1.19417453e+01]),\n",
       " array([ 8.37324945,  0.        ,  8.44098012,  0.        ,  0.        ,\n",
       "         9.14302089,  0.        , 10.88336239]),\n",
       " array([2.50000000e-03, 7.84083323e+00, 0.00000000e+00, 8.05290412e+00,\n",
       "        7.76964423e+00, 0.00000000e+00, 0.00000000e+00, 9.59503748e+00]),\n",
       " array([2.50000000e-03, 6.65101265e+00, 5.80151008e+00, 7.01607669e+00,\n",
       "        0.00000000e+00, 7.55994273e+00, 7.77435535e+00, 0.00000000e+00]),\n",
       " array([5.20104464, 0.        , 5.45383437, 5.27992769, 4.06997922,\n",
       "        6.72870209, 5.85412179, 4.27699128]),\n",
       " array([3.57883574, 3.90045358, 3.10680751, 3.69044696, 3.39481046,\n",
       "        4.70923243, 2.41477164, 7.00176704]),\n",
       " array([2.16456019, 1.88923229, 2.10251188, 2.33545176, 2.3462803 ,\n",
       "        2.74808782, 3.70110262, 4.66648522]),\n",
       " array([0.86099393, 0.85390133, 0.78161287, 0.97062824, 0.87116342,\n",
       "        1.275205  , 1.09367826, 2.67629244]),\n",
       " array([0.00498433, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.99759036])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
