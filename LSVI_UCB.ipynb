{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Has not been fully debugged/optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from scipy.stats import bernoulli\n",
    "#from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    '''General RL environment'''\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    def advance(self, action):\n",
    "        '''\n",
    "        Moves one step in the environment.\n",
    "        Args:\n",
    "            action\n",
    "        Returns:\n",
    "            reward - double - reward\n",
    "            newState - int - new state\n",
    "            pContinue - 0/1 - flag for end of the episode\n",
    "        '''\n",
    "        return 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_riverSwim(epLen=20, nState=5):\n",
    "    '''\n",
    "    Makes the benchmark RiverSwim MDP.\n",
    "    Args:\n",
    "        NULL - works for default implementation\n",
    "    Returns:\n",
    "        riverSwim - Tabular MDP environment '''\n",
    "    nAction = 2\n",
    "    R_true = {}\n",
    "    P_true = {}\n",
    "    states = {}\n",
    "    for s in range(nState):\n",
    "        states[(s)] = 0.0\n",
    "        for a in range(nAction):\n",
    "            R_true[s, a] = (0, 0)\n",
    "            P_true[s, a] = np.zeros(nState)\n",
    "\n",
    "    # Rewards\n",
    "    R_true[0, 0] = (5/1000, 0)\n",
    "    R_true[nState - 1, 1] = (1, 0)\n",
    "\n",
    "    # Transitions\n",
    "    for s in range(nState):\n",
    "        P_true[s, 0][max(0, s-1)] = 1.\n",
    "\n",
    "    for s in range(1, nState - 1):\n",
    "        P_true[s, 1][min(nState - 1, s + 1)] = 0.3\n",
    "        P_true[s, 1][s] = 0.6\n",
    "        P_true[s, 1][max(0, s-1)] = 0.1\n",
    "\n",
    "    P_true[0, 1][0] = 0.3\n",
    "    P_true[0, 1][1] = 0.7\n",
    "    P_true[nState - 1, 1][nState - 1] = 0.9\n",
    "    P_true[nState - 1, 1][nState - 2] = 0.1\n",
    "\n",
    "    riverSwim = TabularMDP(nState, nAction, epLen)\n",
    "    riverSwim.R = R_true\n",
    "    riverSwim.P = P_true\n",
    "    riverSwim.states = states\n",
    "    riverSwim.reset()\n",
    "\n",
    "    return riverSwim\n",
    "\n",
    "class TabularMDP(Environment):\n",
    "    '''\n",
    "    Tabular MDP\n",
    "    R - dict by (s,a) - each R[s,a] = (meanReward, sdReward)\n",
    "    P - dict by (s,a) - each P[s,a] = transition vector size S\n",
    "    '''\n",
    "\n",
    "    def __init__(self, nState, nAction, epLen):\n",
    "        '''\n",
    "        Initialize a tabular episodic MDP\n",
    "        Args:\n",
    "            nState  - int - number of states\n",
    "            nAction - int - number of actions\n",
    "            epLen   - int - episode length\n",
    "        Returns:\n",
    "            Environment object\n",
    "        '''\n",
    "\n",
    "        self.nState = nState\n",
    "        self.nAction = nAction\n",
    "        self.epLen = epLen\n",
    "\n",
    "        self.timestep = 0\n",
    "        self.state = 0\n",
    "\n",
    "        # Now initialize R and P\n",
    "        self.R = {}\n",
    "        self.P = {}\n",
    "        self.states = {}\n",
    "        for state in range(nState):\n",
    "            for action in range(nAction):\n",
    "                self.R[state, action] = (1, 1)\n",
    "                self.P[state, action] = np.ones(nState) / nState\n",
    "                \n",
    "    def reset(self):\n",
    "        \"Resets the Environment\"\n",
    "        self.timestep = 0\n",
    "        self.state = 0\n",
    "        \n",
    "    def advance(self,action):\n",
    "        '''\n",
    "        Move one step in the environment\n",
    "        Args:\n",
    "        action - int - chosen action\n",
    "        Returns:\n",
    "        reward - double - reward\n",
    "        newState - int - new state\n",
    "        episodeEnd - 0/1 - flag for end of the episode\n",
    "        '''\n",
    "        if self.R[self.state, action][1] < 1e-9:\n",
    "            # Hack for no noise\n",
    "            reward = self.R[self.state, action][0]\n",
    "        else:\n",
    "            reward = np.random.normal(loc=self.R[self.state, action][0],\n",
    "                                      scale=self.R[self.state, action][1])\n",
    "        #print(self.state, action, self.P[self.state, action])\n",
    "        newState = np.random.choice(self.nState, p=self.P[self.state, action])\n",
    "        \n",
    "        # Update the environment\n",
    "        self.state = newState\n",
    "        self.timestep += 1\n",
    "\n",
    "        episodeEnd = 0\n",
    "        if self.timestep == self.epLen:\n",
    "            episodeEnd = 1\n",
    "            #newState = None\n",
    "            self.reset()\n",
    "\n",
    "        return reward, newState, episodeEnd\n",
    "    \n",
    "    def argmax(self,b):\n",
    "        #print(b)\n",
    "        return np.random.choice(np.where(b == b.max())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deep_sea(Environment):\n",
    "    '''\n",
    "    Description:\n",
    "        A deep sea environment, where a diver goes\n",
    "        down and each time and she needs to make a\n",
    "        decision to go left or right.\n",
    "        environment terminates after fixed time step\n",
    "\n",
    "    Observation:\n",
    "        [horizontal position, vertical position]\n",
    "\n",
    "    Actions:\n",
    "        2 possible actions:\n",
    "        0 - left\n",
    "        1 - right\n",
    "\n",
    "    Starting State:\n",
    "        start at position 0, time step 0\n",
    "\n",
    "    Episode termination:\n",
    "        Env terminates after fixed number of time steps\n",
    "    '''\n",
    "\n",
    "    def __init__(self, num_steps):\n",
    "        '''\n",
    "        Inputs:\n",
    "            num_steps: An integer that represents the size of the DeepSea environment\n",
    "        '''\n",
    "        self.num_steps = num_steps\n",
    "        self.epLen = num_steps\n",
    "        self.flip_mask = 2*np.random.binomial(1,0.5,(num_steps,num_steps))-1\n",
    "        self.nAction = 2\n",
    "        self.nState = pow(num_steps,2)\n",
    "        self.epLen = num_steps\n",
    "        self.R = {}\n",
    "        self.states = {}\n",
    "        for s in range(self.num_steps):\n",
    "            for s_ in range(self.num_steps):\n",
    "                self.R[(s,s_), 0] = (0, 0)\n",
    "                self.R[(s,s_), 1] = (-0.01/self.nState, 0)\n",
    "                self.states[(s,s_)] = 0\n",
    "        self.R[(self.num_steps-1,self.num_steps-1),1] = (0.99,0)\n",
    "\n",
    "    def name(self):\n",
    "        return  \"deep sea\"\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = (0,0)\n",
    "        self.timestep = 0\n",
    "        return copy.deepcopy(self.state)\n",
    "\n",
    "    def advance(self,action):\n",
    "        assert action in [0,1], \"invalid action\"\n",
    "        self.state_prev = self.state\n",
    "        step_horizontal = (2*action-1)\n",
    "        horizontal = max(self.state[0] + step_horizontal, 0)\n",
    "        vertical = self.state[1] + 1\n",
    "        done =  bool(vertical == self.num_steps)\n",
    "        self.state = (horizontal, vertical)\n",
    "        self.timestep += 1\n",
    "        return self.R[self.state_prev,action][0], copy.deepcopy(self.state), done\n",
    "\n",
    "    def argmax(self,b):\n",
    "        return np.random.choice(np.where(b == b.max())[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSVI_UCB(object):\n",
    "    def __init__(self,env,K,c):\n",
    "        self.env = env\n",
    "        self.K = K\n",
    "        self.d = self.env.nState * self.env.nAction\n",
    "        self.c = c\n",
    "        self.p = 10/self.K\n",
    "        self.lam = 1.0\n",
    "        self.Lam = [(self.lam*np.identity(self.d)) for h in range(env.epLen)]\n",
    "        self.phi = np.identity(self.d)\n",
    "        self.Q = {(h,s,a): 0.0 for h in range(self.env.epLen+1) for s in self.env.states.keys() \\\n",
    "                   for a in range(self.env.nAction)}\n",
    "        self.w = [np.zeros(self.d) for h in range(env.epLen)]\n",
    "        self.wsum = [np.zeros(self.d) for h in range(env.epLen)]\n",
    "        self.buffer = {h: [] for h in range(self.env.epLen)}\n",
    "        self.sigma = {}\n",
    "        self.createSigma()\n",
    "        \n",
    "    def learn(self,s,a,r,s_,h):\n",
    "        self.Lam[h] += np.outer(self.phi[self.sigma[s,a]],self.phi[self.sigma[s,a]])\n",
    "        self.wsum[h] += self.phi[self.sigma[s,a]] * (r + \\\n",
    "                                max(np.array([self.Q[(h+1,s_,a_)] for a_ in range(self.env.nAction)])))\n",
    "        self.w[h] = np.matmul(np.linalg.inv(self.Lam[h]),self.wsum[h])\n",
    "\n",
    "    \n",
    "    def update_Q(self,k):\n",
    "        for h in range(env.epLen-1,-1,-1):\n",
    "            for s in self.env.states.keys():\n",
    "                for a in range(env.nAction):\n",
    "                    min1 = np.dot(self.w[h],self.phi[self.sigma[s,a]]) + self.Beta(h,k)* \\\n",
    "                                  np.sqrt(np.dot(np.dot(self.phi[self.sigma[s,a]].T,np.linalg.inv(self.Lam[h])) \\\n",
    "                                                  ,self.phi[self.sigma[s,a]]))\n",
    "                    min2 = self.env.epLen\n",
    "                    self.Q[h,s,a] = self.proj(min1,0,self.env.epLen)\n",
    "    \n",
    "    def Beta(self,h,k):\n",
    "        \n",
    "        #first = np.sqrt(self.lam)*self.c\n",
    "        #second = np.sqrt(2*np.log(1/self.delta) + self.d*np.log((self.d*self.lam + k*self.L*self.L)/(self.d*self.lam)))\n",
    "        #second = np.sqrt(2*np.log(1/self.p) + np.log(k*min(np.linalg.det(self.Lam[h]),pow(10,10)) / (pow(self.lam,self.d))))\n",
    "        #return first + second\n",
    "        \n",
    "        \n",
    "        itoa = np.log(2*self.d*self.K*self.env.epLen/self.p)\n",
    "        return self.c*self.d*self.env.epLen*np.sqrt(itoa)\n",
    "    \n",
    "    def createSigma(self):\n",
    "        '''\n",
    "        A simple function that creates sigma according to Appendix B.\n",
    "        Here sigma is a dictionary who inputs is a tuple (s,a,s') and stores\n",
    "        the interger index to be used in our basis model P.\n",
    "        '''\n",
    "        i = 0\n",
    "        for s in self.env.states.keys():\n",
    "            for a in range(env.nAction):\n",
    "                self.sigma[(s,a)] = int(i)\n",
    "                i += 1\n",
    "    \n",
    "    def act(self,s,h):\n",
    "        x = np.array([self.Q[(h,s,a)] for a in range(self.env.nAction)])\n",
    "        return self.env.argmax(x)\n",
    "    \n",
    "    def proj(self,x, lo, hi):\n",
    "        return max(min(x,hi),lo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_riverSwim(epLen = 20, nState = 4)\n",
    "K = 10000\n",
    "c = 1.0\n",
    "agent = LSVI_UCB(env,K,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a12f9a5b92a4d0190b38b4193255e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "R = 0\n",
    "Rvec = []\n",
    "for k in (range(1,K+1)):\n",
    "    env.reset()\n",
    "    done = 0\n",
    "    while done != 1:\n",
    "        s = env.state\n",
    "        h = env.timestep\n",
    "        a = agent.act(s,h)\n",
    "        if k == K:\n",
    "            print(a)\n",
    "        r,s_,done = env.advance(a)\n",
    "        R+=r\n",
    "        agent.learn(s,a,r,s_,h)\n",
    "    Rvec.append(R)\n",
    "    agent.update_Q(k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a1c4af2b0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Rvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0, 0): 20,\n",
       " (0, 0, 1): 20,\n",
       " (0, 1, 0): 20,\n",
       " (0, 1, 1): 20,\n",
       " (0, 2, 0): 20,\n",
       " (0, 2, 1): 20,\n",
       " (0, 3, 0): 20,\n",
       " (0, 3, 1): 20,\n",
       " (1, 0, 0): 20,\n",
       " (1, 0, 1): 20,\n",
       " (1, 1, 0): 20,\n",
       " (1, 1, 1): 20,\n",
       " (1, 2, 0): 20,\n",
       " (1, 2, 1): 20,\n",
       " (1, 3, 0): 20,\n",
       " (1, 3, 1): 20,\n",
       " (2, 0, 0): 20,\n",
       " (2, 0, 1): 20,\n",
       " (2, 1, 0): 20,\n",
       " (2, 1, 1): 20,\n",
       " (2, 2, 0): 20,\n",
       " (2, 2, 1): 20,\n",
       " (2, 3, 0): 20,\n",
       " (2, 3, 1): 20,\n",
       " (3, 0, 0): 20,\n",
       " (3, 0, 1): 20,\n",
       " (3, 1, 0): 20,\n",
       " (3, 1, 1): 20,\n",
       " (3, 2, 0): 20,\n",
       " (3, 2, 1): 20,\n",
       " (3, 3, 0): 20,\n",
       " (3, 3, 1): 20,\n",
       " (4, 0, 0): 20,\n",
       " (4, 0, 1): 20,\n",
       " (4, 1, 0): 20,\n",
       " (4, 1, 1): 20,\n",
       " (4, 2, 0): 20,\n",
       " (4, 2, 1): 20,\n",
       " (4, 3, 0): 20,\n",
       " (4, 3, 1): 20,\n",
       " (5, 0, 0): 20,\n",
       " (5, 0, 1): 20,\n",
       " (5, 1, 0): 20,\n",
       " (5, 1, 1): 20,\n",
       " (5, 2, 0): 20,\n",
       " (5, 2, 1): 20,\n",
       " (5, 3, 0): 20,\n",
       " (5, 3, 1): 20,\n",
       " (6, 0, 0): 20,\n",
       " (6, 0, 1): 20,\n",
       " (6, 1, 0): 20,\n",
       " (6, 1, 1): 20,\n",
       " (6, 2, 0): 20,\n",
       " (6, 2, 1): 20,\n",
       " (6, 3, 0): 20,\n",
       " (6, 3, 1): 20,\n",
       " (7, 0, 0): 20,\n",
       " (7, 0, 1): 20,\n",
       " (7, 1, 0): 20,\n",
       " (7, 1, 1): 20,\n",
       " (7, 2, 0): 20,\n",
       " (7, 2, 1): 20,\n",
       " (7, 3, 0): 20,\n",
       " (7, 3, 1): 20,\n",
       " (8, 0, 0): 20,\n",
       " (8, 0, 1): 20,\n",
       " (8, 1, 0): 20,\n",
       " (8, 1, 1): 20,\n",
       " (8, 2, 0): 20,\n",
       " (8, 2, 1): 20,\n",
       " (8, 3, 0): 20,\n",
       " (8, 3, 1): 20,\n",
       " (9, 0, 0): 20,\n",
       " (9, 0, 1): 20,\n",
       " (9, 1, 0): 20,\n",
       " (9, 1, 1): 20,\n",
       " (9, 2, 0): 20,\n",
       " (9, 2, 1): 20,\n",
       " (9, 3, 0): 20,\n",
       " (9, 3, 1): 20,\n",
       " (10, 0, 0): 20,\n",
       " (10, 0, 1): 20,\n",
       " (10, 1, 0): 20,\n",
       " (10, 1, 1): 20,\n",
       " (10, 2, 0): 20,\n",
       " (10, 2, 1): 20,\n",
       " (10, 3, 0): 20,\n",
       " (10, 3, 1): 20,\n",
       " (11, 0, 0): 20,\n",
       " (11, 0, 1): 20,\n",
       " (11, 1, 0): 20,\n",
       " (11, 1, 1): 20,\n",
       " (11, 2, 0): 20,\n",
       " (11, 2, 1): 20,\n",
       " (11, 3, 0): 20,\n",
       " (11, 3, 1): 20,\n",
       " (12, 0, 0): 20,\n",
       " (12, 0, 1): 20,\n",
       " (12, 1, 0): 20,\n",
       " (12, 1, 1): 20,\n",
       " (12, 2, 0): 20,\n",
       " (12, 2, 1): 20,\n",
       " (12, 3, 0): 20,\n",
       " (12, 3, 1): 20,\n",
       " (13, 0, 0): 20,\n",
       " (13, 0, 1): 20,\n",
       " (13, 1, 0): 20,\n",
       " (13, 1, 1): 20,\n",
       " (13, 2, 0): 20,\n",
       " (13, 2, 1): 20,\n",
       " (13, 3, 0): 20,\n",
       " (13, 3, 1): 20,\n",
       " (14, 0, 0): 20,\n",
       " (14, 0, 1): 20,\n",
       " (14, 1, 0): 20,\n",
       " (14, 1, 1): 20,\n",
       " (14, 2, 0): 20,\n",
       " (14, 2, 1): 20,\n",
       " (14, 3, 0): 20,\n",
       " (14, 3, 1): 20,\n",
       " (15, 0, 0): 20,\n",
       " (15, 0, 1): 20,\n",
       " (15, 1, 0): 20,\n",
       " (15, 1, 1): 20,\n",
       " (15, 2, 0): 20,\n",
       " (15, 2, 1): 20,\n",
       " (15, 3, 0): 20,\n",
       " (15, 3, 1): 20,\n",
       " (16, 0, 0): 20,\n",
       " (16, 0, 1): 20,\n",
       " (16, 1, 0): 20,\n",
       " (16, 1, 1): 20,\n",
       " (16, 2, 0): 20,\n",
       " (16, 2, 1): 20,\n",
       " (16, 3, 0): 20,\n",
       " (16, 3, 1): 20,\n",
       " (17, 0, 0): 20,\n",
       " (17, 0, 1): 20,\n",
       " (17, 1, 0): 20,\n",
       " (17, 1, 1): 20,\n",
       " (17, 2, 0): 20,\n",
       " (17, 2, 1): 20,\n",
       " (17, 3, 0): 20,\n",
       " (17, 3, 1): 20,\n",
       " (18, 0, 0): 20,\n",
       " (18, 0, 1): 20,\n",
       " (18, 1, 0): 20,\n",
       " (18, 1, 1): 20,\n",
       " (18, 2, 0): 20,\n",
       " (18, 2, 1): 20,\n",
       " (18, 3, 0): 20,\n",
       " (18, 3, 1): 20,\n",
       " (19, 0, 0): 14.464053373753112,\n",
       " (19, 0, 1): 14.461753579513454,\n",
       " (19, 1, 0): 17.872796866196598,\n",
       " (19, 1, 1): 17.877893913745307,\n",
       " (19, 2, 0): 20,\n",
       " (19, 2, 1): 20,\n",
       " (19, 3, 0): 20,\n",
       " (19, 3, 1): 20,\n",
       " (20, 0, 0): 0.0,\n",
       " (20, 0, 1): 0.0,\n",
       " (20, 1, 0): 0.0,\n",
       " (20, 1, 1): 0.0,\n",
       " (20, 2, 0): 0.0,\n",
       " (20, 2, 1): 0.0,\n",
       " (20, 3, 0): 0.0,\n",
       " (20, 3, 1): 0.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
